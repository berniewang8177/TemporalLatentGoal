
Random seed for training set as 2
In total, 36.662521 M # of params
get instruction path: /home/yiqiw2/experiment/language_rl/train_datasets/push_buttons+1
Num ep. 100
get instruction path: /home/yiqiw2/experiment/language_rl/val_datasets/push_buttons+1
Num ep. 10
get instruction path: /home/yiqiw2/experiment/language_rl/val_datasets/push_buttons+7
Num ep. 20
  0%|                                                                                                                 | 0/1000 [00:00<?, ?it/s]/home/yiqiw2/miniconda3/envs/rlnlp/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: replication_pad2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:82.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yiqiw2/miniconda3/envs/rlnlp/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: upsample_bilinear2d_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:82.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass


















































































 30%|██████████████████████████████▋                                                                        | 298/1000 [02:57<06:58,  1.68it/s]
Traceback (most recent call last):
  File "/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Scripts2/train.py", line 78, in <module>
    training(
  File "/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/training.py", line 141, in training
    gc.collect()
KeyboardInterrupt