
Random seed for training set as 2
In total, 0.792953 M # of params
get instruction path: /home/yiqiw2/experiment/language_rl/train_datasets/push_buttons+2
Num ep. 100
get instruction path: /home/yiqiw2/experiment/language_rl/val_datasets/push_buttons+2
Num ep. 10
  0%|          | 0/1000 [00:00<?, ?it/s]/home/yiqiw2/miniconda3/envs/rlnlp/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: replication_pad2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:82.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yiqiw2/miniconda3/envs/rlnlp/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: upsample_bilinear2d_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:82.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass















































  5%|▌         | 50/1000 [03:40<7:56:06, 30.07s/it]














































 10%|█         | 100/1000 [07:19<7:07:24, 28.49s/it]















































 15%|█▌        | 150/1000 [10:43<6:18:05, 26.69s/it]

















































 20%|██        | 200/1000 [14:29<6:28:34, 29.14s/it]















































 25%|██▌       | 250/1000 [18:05<5:38:16, 27.06s/it]

















































 30%|███       | 300/1000 [21:52<5:30:31, 28.33s/it]


















































 35%|███▌      | 350/1000 [25:14<4:08:39, 22.95s/it]















































 40%|███▉      | 399/1000 [27:25<25:24,  2.54s/it]















































 45%|████▍     | 449/1000 [30:55<44:42,  4.87s/it]















































 50%|████▉     | 499/1000 [34:23<17:35,  2.11s/it]















































 55%|█████▍    | 549/1000 [37:33<19:03,  2.54s/it]

















































 60%|█████▉    | 599/1000 [40:46<14:37,  2.19s/it]














































 65%|██████▍   | 649/1000 [43:57<11:07,  1.90s/it]

















































 70%|██████▉   | 699/1000 [46:59<13:02,  2.60s/it]

















































 75%|███████▍  | 749/1000 [50:12<09:45,  2.33s/it]
















































 80%|████████  | 800/1000 [54:18<1:09:51, 20.96s/it]













































 85%|████████▍ | 849/1000 [56:15<05:21,  2.13s/it]















































 90%|████████▉ | 899/1000 [59:19<06:15,  3.72s/it]















































 95%|█████████▍| 949/1000 [1:02:27<01:47,  2.11s/it]














































100%|█████████▉| 999/1000 [1:05:35<00:02,  2.06s/it]

100%|██████████| 1000/1000 [1:06:44<00:00,  4.00s/it]