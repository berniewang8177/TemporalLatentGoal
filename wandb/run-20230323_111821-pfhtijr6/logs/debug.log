2023-03-23 11:18:21,866 INFO    MainThread:71344 [wandb_setup.py:_flush():68] Configure stats pid to 71344
2023-03-23 11:18:21,866 INFO    MainThread:71344 [wandb_setup.py:_flush():68] Loading settings from /home/yiqiw2/.config/wandb/settings
2023-03-23 11:18:21,866 INFO    MainThread:71344 [wandb_setup.py:_flush():68] Loading settings from /home/yiqiw2/experiment/language_rl/TemporalLatentGoal/wandb/settings
2023-03-23 11:18:21,866 INFO    MainThread:71344 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}
2023-03-23 11:18:21,866 INFO    MainThread:71344 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'Scripts2/train.py', 'program': '/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Scripts2/train.py'}
2023-03-23 11:18:21,866 INFO    MainThread:71344 [wandb_init.py:_log_setup():492] Logging user logs to /home/yiqiw2/experiment/language_rl/TemporalLatentGoal/wandb/run-20230323_111821-pfhtijr6/logs/debug.log
2023-03-23 11:18:21,866 INFO    MainThread:71344 [wandb_init.py:_log_setup():493] Logging internal logs to /home/yiqiw2/experiment/language_rl/TemporalLatentGoal/wandb/run-20230323_111821-pfhtijr6/logs/debug-internal.log
2023-03-23 11:18:21,866 INFO    MainThread:71344 [wandb_init.py:init():532] calling init triggers
2023-03-23 11:18:21,867 INFO    MainThread:71344 [wandb_init.py:init():538] wandb.init called with sweep_config: {}
config: {'_initialized': True, '_explicit_bool': False, '_underscores_to_dashes': False, '_parsed': True, 'extra_args': [], 'argument_buffer': OrderedDict([('help', (('-h', '--help'), {'action': 'help', 'default': '==SUPPRESS==', 'help': 'show this help message and exit'}))]), '_subparser_buffer': [], 'class_variables': OrderedDict([('accumulate_grad_batches', {'comment': ''}), ('cameras', {'comment': ''}), ('checkpoint', {'comment': ''}), ('checkpoint_period', {'comment': ''}), ('dataset', {'comment': ''}), ('dataset_val', {'comment': ''}), ('device', {'comment': ''}), ('xp', {'comment': ''}), ('name', {'comment': ''}), ('num_workers', {'comment': ''}), ('max_tries', {'comment': ''}), ('max_episodes_per_taskvar', {'comment': ''}), ('instructions', {'comment': ''}), ('cache_size', {'comment': ''}), ('lang_emb', {'comment': ''}), ('seed', {'comment': ''}), ('tasks', {'comment': '# if multi-tasks, then "task_a task_b task_c "'}), ('variations', {'comment': 'if variations 1 2 3 then "1 2 3"'}), ('val_variations', {'comment': ''}), ('episodes_json_path', {'comment': ''}), ('val_number', {'comment': 'frequency of validation'}), ('batch_size', {'comment': ''}), ('lr', {'comment': ''}), ('warmup', {'comment': ''}), ('val_batch_size', {'comment': 'given the fact that the dataset has only 10 episodes'}), ('train_iters', {'comment': ''}), ('jitter', {'comment': ''}), ('load_model', {'comment': ''}), ('load_name', {'comment': ''}), ('save_model', {'comment': 'whether saviing the best model'}), ('save_path', {'comment': ''}), ('headless', {'comment': ''}), ('output', {'comment': ''}), ('depth', {'comment': ''}), ('dim_feedforward', {'comment': ''}), ('hidden_dim', {'comment': 'used for visual tokens'}), ('instr_size', {'comment': ''}), ('mask_obs_prob', {'comment': ''}), ('num_layers', {'comment': ''}), ('cross_layers', {'comment': "will be double for LAVA since it doesn't have policy"}), ('policy_layers', {'comment': ''}), ('expert_counts', {'comment': 'default 1, if using VALA, then 6 = 2 modalities x 3 views'}), ('modality_fusion', {'comment': 'whether we fuse lang_goal and vision or not'}), ('position_offset', {'comment': ''}), ('lang_offset', {'comment': ''}), ('offset_emb', {'comment': 'add multi-view and time embedding before making a prediction'}), ('no_film', {'comment': 'use for debuggging'}), ('max_episode_length', {'comment': ''}), ('oracle_goal', {'comment': 'we manually provide sub-goal per step'}), ('log_to_wandb', {'comment': ''})]), '_annotations': {'accumulate_grad_batches': <class 'int'>, 'cameras': typing.Tuple[str, ...], 'checkpoint': typing.Optional[pathlib.Path], 'checkpoint_period': <class 'int'>, 'dataset': typing.List[pathlib.Path], 'dataset_val': typing.List[pathlib.Path], 'device': <class 'str'>, 'xp': <class 'pathlib.Path'>, 'name': <class 'str'>, 'num_workers': <class 'int'>, 'max_tries': <class 'int'>, 'max_episodes_per_taskvar': <class 'int'>, 'instructions': typing.Optional[pathlib.Path], 'cache_size': <class 'int'>, 'lang_emb': <class 'str'>, 'seed': <class 'int'>, 'tasks': <class 'str'>, 'variations': <class 'str'>, 'val_variations': <class 'str'>, 'episodes_json_path': <class 'str'>, 'val_number': <class 'int'>, 'batch_size': <class 'int'>, 'lr': <class 'float'>, 'warmup': <class 'int'>, 'val_batch_size': <class 'int'>, 'train_iters': <class 'int'>, 'jitter': <class 'bool'>, 'load_model': <class 'bool'>, 'load_name': <class 'str'>, 'save_model': <class 'bool'>, 'save_path': <class 'str'>, 'headless': <class 'bool'>, 'output': <class 'pathlib.Path'>, 'depth': <class 'int'>, 'dim_feedforward': <class 'int'>, 'hidden_dim': <class 'int'>, 'instr_size': <class 'int'>, 'mask_obs_prob': <class 'float'>, 'num_layers': <class 'int'>, 'cross_layers': <class 'int'>, 'policy_layers': <class 'int'>, 'expert_counts': <class 'int'>, 'modality_fusion': <class 'bool'>, 'position_offset': <class 'bool'>, 'lang_offset': <class 'bool'>, 'offset_emb': <class 'bool'>, 'no_film': <class 'bool'>, 'max_episode_length': <class 'int'>, 'oracle_goal': <class 'bool'>, 'log_to_wandb': <class 'bool'>}, 'description': None, 'argument_default': None, 'prefix_chars': '-', 'conflict_handler': 'error', '_registries': {'action': {None: <class 'argparse._StoreAction'>, 'store': <class 'argparse._StoreAction'>, 'store_const': <class 'argparse._StoreConstAction'>, 'store_true': <class 'argparse._StoreTrueAction'>, 'store_false': <class 'argparse._StoreFalseAction'>, 'append': <class 'argparse._AppendAction'>, 'append_const': <class 'argparse._AppendConstAction'>, 'count': <class 'argparse._CountAction'>, 'help': <class 'argparse._HelpAction'>, 'version': <class 'argparse._VersionAction'>, 'parsers': <class 'argparse._SubParsersAction'>, 'extend': <class 'argparse._ExtendAction'>}, 'type': {None: <function ArgumentParser.__init__.<locals>.identity at 0x7fc162555160>}}, '_actions': [_StoreAction(option_strings=['--accumulate_grad_batches'], dest='accumulate_grad_batches', nargs=None, const=None, default=2, type=<class 'int'>, choices=None, required=False, help='(int, default=2) ', metavar=None), _StoreAction(option_strings=['--cameras'], dest='cameras', nargs='*', const=None, default=('wrist', 'left_shoulder', 'right_shoulder'), type=<tap.utils.TupleTypeEnforcer object at 0x7fc14526bfa0>, choices=None, required=False, help="(Tuple[str, ...], default=('wrist', 'left_shoulder', 'right_shoulder')) ", metavar=None), _StoreAction(option_strings=['--checkpoint'], dest='checkpoint', nargs=None, const=None, default=None, type=<class 'pathlib.Path'>, choices=None, required=False, help='(Optional[pathlib.Path], default=None) ', metavar=None), _StoreAction(option_strings=['--checkpoint_period'], dest='checkpoint_period', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='(int, default=10) ', metavar=None), _StoreAction(option_strings=['--dataset'], dest='dataset', nargs='*', const=None, default=['/home/yiqiw2/experiment/language_rl/train_datasets/'], type=<class 'pathlib.Path'>, choices=None, required=False, help="(List[pathlib.Path], default=['/home/yiqiw2/experiment/language_rl/train_datasets/']) ", metavar=None), _StoreAction(option_strings=['--dataset_val'], dest='dataset_val', nargs='*', const=None, default=['/home/yiqiw2/experiment/language_rl/val_datasets/'], type=<class 'pathlib.Path'>, choices=None, required=False, help="(List[pathlib.Path], default=['/home/yiqiw2/experiment/language_rl/val_datasets/']) ", metavar=None), _StoreAction(option_strings=['--device'], dest='device', nargs=None, const=None, default='cuda:0', type=<class 'str'>, choices=None, required=False, help='(str, default=cuda:0) ', metavar=None), _StoreAction(option_strings=['--xp'], dest='xp', nargs=None, const=None, default=PosixPath('/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/xp'), type=<class 'pathlib.Path'>, choices=None, required=False, help='(Path, default=/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/xp) ', metavar=None), _StoreAction(option_strings=['--name'], dest='name', nargs=None, const=None, default='LAVA', type=<class 'str'>, choices=None, required=False, help='(str, default=LAVA) ', metavar=None), _StoreAction(option_strings=['--num_workers'], dest='num_workers', nargs=None, const=None, default=5, type=<class 'int'>, choices=None, required=False, help='(int, default=5) ', metavar=None), _StoreAction(option_strings=['--max_tries'], dest='max_tries', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='(int, default=10) ', metavar=None), _StoreAction(option_strings=['--max_episodes_per_taskvar'], dest='max_episodes_per_taskvar', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, required=False, help='(int, default=100) ', metavar=None), _StoreAction(option_strings=['--instructions'], dest='instructions', nargs=None, const=None, default=None, type=<class 'pathlib.Path'>, choices=None, required=False, help='(Optional[pathlib.Path], default=None) ', metavar=None), _StoreAction(option_strings=['--cache_size'], dest='cache_size', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, required=False, help='(int, default=100) ', metavar=None), _StoreAction(option_strings=['--lang_emb'], dest='lang_emb', nargs=None, const=None, default='CLIP', type=<class 'str'>, choices=None, required=False, help='(str, default=CLIP) ', metavar=None), _StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=2, type=<class 'int'>, choices=None, required=False, help='(int, default=2) ', metavar=None), _StoreAction(option_strings=['--tasks'], dest='tasks', nargs=None, const=None, default='push_buttons', type=<class 'str'>, choices=None, required=False, help='(str, default=push_buttons) # if multi-tasks, then "task_a task_b task_c "', metavar=None), _StoreAction(option_strings=['--variations'], dest='variations', nargs=None, const=None, default='1 ', type=<class 'str'>, choices=None, required=False, help='(str, default=1 ) if variations 1 2 3 then "1 2 3"', metavar=None), _StoreAction(option_strings=['--val_variations'], dest='val_variations', nargs=None, const=None, default='7 ', type=<class 'str'>, choices=None, required=False, help='(str, default=7 ) ', metavar=None), _StoreAction(option_strings=['--episodes_json_path'], dest='episodes_json_path', nargs=None, const=None, default='/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Preprocess/episodes.json', type=<class 'str'>, choices=None, required=False, help='(str, default=/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Preprocess/episodes.json) ', metavar=None), _StoreAction(option_strings=['--val_number'], dest='val_number', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='(int, default=10) frequency of validation', metavar=None), _StoreAction(option_strings=['--batch_size'], dest='batch_size', nargs=None, const=None, default=32, type=<class 'int'>, choices=None, required=False, help='(int, default=32) ', metavar=None), _StoreAction(option_strings=['--lr'], dest='lr', nargs=None, const=None, default=0.001, type=<class 'float'>, choices=None, required=False, help='(float, default=0.001) ', metavar=None), _StoreAction(option_strings=['--warmup'], dest='warmup', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, required=False, help='(int, default=100) ', metavar=None), _StoreAction(option_strings=['--val_batch_size'], dest='val_batch_size', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, required=False, help='(int, default=1) given the fact that the dataset has only 10 episodes', metavar=None), _StoreAction(option_strings=['--train_iters'], dest='train_iters', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, required=False, help='(int, default=100) ', metavar=None), _StoreTrueAction(option_strings=['--jitter'], dest='jitter', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) ', metavar=None), _StoreTrueAction(option_strings=['--load_model'], dest='load_model', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) ', metavar=None), _StoreAction(option_strings=['--load_name'], dest='load_name', nargs=None, const=None, default='', type=<class 'str'>, choices=None, required=False, help='(str, default=) ', metavar=None), _StoreTrueAction(option_strings=['--save_model'], dest='save_model', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) whether saviing the best model', metavar=None), _StoreAction(option_strings=['--save_path'], dest='save_path', nargs=None, const=None, default='/home/yiqiw2/experiment/language_rl/saved_model', type=<class 'str'>, choices=None, required=False, help='(str, default=/home/yiqiw2/experiment/language_rl/saved_model) ', metavar=None), _StoreFalseAction(option_strings=['--headless'], dest='headless', nargs=0, const=False, default=True, type=None, choices=None, required=False, help='(bool, default=True) ', metavar=None), _StoreAction(option_strings=['--output'], dest='output', nargs=None, const=None, default=PosixPath('/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/records.txt'), type=<class 'pathlib.Path'>, choices=None, required=False, help='(Path, default=/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/records.txt) ', metavar=None), _StoreAction(option_strings=['--depth'], dest='depth', nargs=None, const=None, default=5, type=<class 'int'>, choices=None, required=False, help='(int, default=5) ', metavar=None), _StoreAction(option_strings=['--dim_feedforward'], dest='dim_feedforward', nargs=None, const=None, default=512, type=<class 'int'>, choices=None, required=False, help='(int, default=512) ', metavar=None), _StoreAction(option_strings=['--hidden_dim'], dest='hidden_dim', nargs=None, const=None, default=32, type=<class 'int'>, choices=None, required=False, help='(int, default=32) used for visual tokens', metavar=None), _StoreAction(option_strings=['--instr_size'], dest='instr_size', nargs=None, const=None, default=512, type=<class 'int'>, choices=None, required=False, help='(int, default=512) ', metavar=None), _StoreAction(option_strings=['--mask_obs_prob'], dest='mask_obs_prob', nargs=None, const=None, default=0.0, type=<class 'float'>, choices=None, required=False, help='(float, default=0.0) ', metavar=None), _StoreAction(option_strings=['--num_layers'], dest='num_layers', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, required=False, help='(int, default=1) ', metavar=None), _StoreAction(option_strings=['--cross_layers'], dest='cross_layers', nargs=None, const=None, default=3, type=<class 'int'>, choices=None, required=False, help="(int, default=3) will be double for LAVA since it doesn't have policy", metavar=None), _StoreAction(option_strings=['--policy_layers'], dest='policy_layers', nargs=None, const=None, default=3, type=<class 'int'>, choices=None, required=False, help='(int, default=3) ', metavar=None), _StoreAction(option_strings=['--expert_counts'], dest='expert_counts', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, required=False, help='(int, default=1) default 1, if using VALA, then 6 = 2 modalities x 3 views', metavar=None), _StoreTrueAction(option_strings=['--modality_fusion'], dest='modality_fusion', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) whether we fuse lang_goal and vision or not', metavar=None), _StoreFalseAction(option_strings=['--position_offset'], dest='position_offset', nargs=0, const=False, default=True, type=None, choices=None, required=False, help='(bool, default=True) ', metavar=None), _StoreTrueAction(option_strings=['--lang_offset'], dest='lang_offset', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) ', metavar=None), _StoreTrueAction(option_strings=['--offset_emb'], dest='offset_emb', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) add multi-view and time embedding before making a prediction', metavar=None), _StoreFalseAction(option_strings=['--no_film'], dest='no_film', nargs=0, const=False, default=True, type=None, choices=None, required=False, help='(bool, default=True) use for debuggging', metavar=None), _StoreAction(option_strings=['--max_episode_length'], dest='max_episode_length', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='(int, default=10) ', metavar=None), _StoreTrueAction(option_strings=['--oracle_goal'], dest='oracle_goal', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) we manually provide sub-goal per step', metavar=None), _StoreTrueAction(option_strings=['--log_to_wandb'], dest='log_to_wandb', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) ', metavar=None), _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, required=False, help='show this help message and exit', metavar=None)], '_option_string_actions': {'--accumulate_grad_batches': _StoreAction(option_strings=['--accumulate_grad_batches'], dest='accumulate_grad_batches', nargs=None, const=None, default=2, type=<class 'int'>, choices=None, required=False, help='(int, default=2) ', metavar=None), '--cameras': _StoreAction(option_strings=['--cameras'], dest='cameras', nargs='*', const=None, default=('wrist', 'left_shoulder', 'right_shoulder'), type=<tap.utils.TupleTypeEnforcer object at 0x7fc14526bfa0>, choices=None, required=False, help="(Tuple[str, ...], default=('wrist', 'left_shoulder', 'right_shoulder')) ", metavar=None), '--checkpoint': _StoreAction(option_strings=['--checkpoint'], dest='checkpoint', nargs=None, const=None, default=None, type=<class 'pathlib.Path'>, choices=None, required=False, help='(Optional[pathlib.Path], default=None) ', metavar=None), '--checkpoint_period': _StoreAction(option_strings=['--checkpoint_period'], dest='checkpoint_period', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='(int, default=10) ', metavar=None), '--dataset': _StoreAction(option_strings=['--dataset'], dest='dataset', nargs='*', const=None, default=['/home/yiqiw2/experiment/language_rl/train_datasets/'], type=<class 'pathlib.Path'>, choices=None, required=False, help="(List[pathlib.Path], default=['/home/yiqiw2/experiment/language_rl/train_datasets/']) ", metavar=None), '--dataset_val': _StoreAction(option_strings=['--dataset_val'], dest='dataset_val', nargs='*', const=None, default=['/home/yiqiw2/experiment/language_rl/val_datasets/'], type=<class 'pathlib.Path'>, choices=None, required=False, help="(List[pathlib.Path], default=['/home/yiqiw2/experiment/language_rl/val_datasets/']) ", metavar=None), '--device': _StoreAction(option_strings=['--device'], dest='device', nargs=None, const=None, default='cuda:0', type=<class 'str'>, choices=None, required=False, help='(str, default=cuda:0) ', metavar=None), '--xp': _StoreAction(option_strings=['--xp'], dest='xp', nargs=None, const=None, default=PosixPath('/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/xp'), type=<class 'pathlib.Path'>, choices=None, required=False, help='(Path, default=/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/xp) ', metavar=None), '--name': _StoreAction(option_strings=['--name'], dest='name', nargs=None, const=None, default='LAVA', type=<class 'str'>, choices=None, required=False, help='(str, default=LAVA) ', metavar=None), '--num_workers': _StoreAction(option_strings=['--num_workers'], dest='num_workers', nargs=None, const=None, default=5, type=<class 'int'>, choices=None, required=False, help='(int, default=5) ', metavar=None), '--max_tries': _StoreAction(option_strings=['--max_tries'], dest='max_tries', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='(int, default=10) ', metavar=None), '--max_episodes_per_taskvar': _StoreAction(option_strings=['--max_episodes_per_taskvar'], dest='max_episodes_per_taskvar', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, required=False, help='(int, default=100) ', metavar=None), '--instructions': _StoreAction(option_strings=['--instructions'], dest='instructions', nargs=None, const=None, default=None, type=<class 'pathlib.Path'>, choices=None, required=False, help='(Optional[pathlib.Path], default=None) ', metavar=None), '--cache_size': _StoreAction(option_strings=['--cache_size'], dest='cache_size', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, required=False, help='(int, default=100) ', metavar=None), '--lang_emb': _StoreAction(option_strings=['--lang_emb'], dest='lang_emb', nargs=None, const=None, default='CLIP', type=<class 'str'>, choices=None, required=False, help='(str, default=CLIP) ', metavar=None), '--seed': _StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=2, type=<class 'int'>, choices=None, required=False, help='(int, default=2) ', metavar=None), '--tasks': _StoreAction(option_strings=['--tasks'], dest='tasks', nargs=None, const=None, default='push_buttons', type=<class 'str'>, choices=None, required=False, help='(str, default=push_buttons) # if multi-tasks, then "task_a task_b task_c "', metavar=None), '--variations': _StoreAction(option_strings=['--variations'], dest='variations', nargs=None, const=None, default='1 ', type=<class 'str'>, choices=None, required=False, help='(str, default=1 ) if variations 1 2 3 then "1 2 3"', metavar=None), '--val_variations': _StoreAction(option_strings=['--val_variations'], dest='val_variations', nargs=None, const=None, default='7 ', type=<class 'str'>, choices=None, required=False, help='(str, default=7 ) ', metavar=None), '--episodes_json_path': _StoreAction(option_strings=['--episodes_json_path'], dest='episodes_json_path', nargs=None, const=None, default='/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Preprocess/episodes.json', type=<class 'str'>, choices=None, required=False, help='(str, default=/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Preprocess/episodes.json) ', metavar=None), '--val_number': _StoreAction(option_strings=['--val_number'], dest='val_number', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='(int, default=10) frequency of validation', metavar=None), '--batch_size': _StoreAction(option_strings=['--batch_size'], dest='batch_size', nargs=None, const=None, default=32, type=<class 'int'>, choices=None, required=False, help='(int, default=32) ', metavar=None), '--lr': _StoreAction(option_strings=['--lr'], dest='lr', nargs=None, const=None, default=0.001, type=<class 'float'>, choices=None, required=False, help='(float, default=0.001) ', metavar=None), '--warmup': _StoreAction(option_strings=['--warmup'], dest='warmup', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, required=False, help='(int, default=100) ', metavar=None), '--val_batch_size': _StoreAction(option_strings=['--val_batch_size'], dest='val_batch_size', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, required=False, help='(int, default=1) given the fact that the dataset has only 10 episodes', metavar=None), '--train_iters': _StoreAction(option_strings=['--train_iters'], dest='train_iters', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, required=False, help='(int, default=100) ', metavar=None), '--jitter': _StoreTrueAction(option_strings=['--jitter'], dest='jitter', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) ', metavar=None), '--load_model': _StoreTrueAction(option_strings=['--load_model'], dest='load_model', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) ', metavar=None), '--load_name': _StoreAction(option_strings=['--load_name'], dest='load_name', nargs=None, const=None, default='', type=<class 'str'>, choices=None, required=False, help='(str, default=) ', metavar=None), '--save_model': _StoreTrueAction(option_strings=['--save_model'], dest='save_model', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) whether saviing the best model', metavar=None), '--save_path': _StoreAction(option_strings=['--save_path'], dest='save_path', nargs=None, const=None, default='/home/yiqiw2/experiment/language_rl/saved_model', type=<class 'str'>, choices=None, required=False, help='(str, default=/home/yiqiw2/experiment/language_rl/saved_model) ', metavar=None), '--headless': _StoreFalseAction(option_strings=['--headless'], dest='headless', nargs=0, const=False, default=True, type=None, choices=None, required=False, help='(bool, default=True) ', metavar=None), '--output': _StoreAction(option_strings=['--output'], dest='output', nargs=None, const=None, default=PosixPath('/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/records.txt'), type=<class 'pathlib.Path'>, choices=None, required=False, help='(Path, default=/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/records.txt) ', metavar=None), '--depth': _StoreAction(option_strings=['--depth'], dest='depth', nargs=None, const=None, default=5, type=<class 'int'>, choices=None, required=False, help='(int, default=5) ', metavar=None), '--dim_feedforward': _StoreAction(option_strings=['--dim_feedforward'], dest='dim_feedforward', nargs=None, const=None, default=512, type=<class 'int'>, choices=None, required=False, help='(int, default=512) ', metavar=None), '--hidden_dim': _StoreAction(option_strings=['--hidden_dim'], dest='hidden_dim', nargs=None, const=None, default=32, type=<class 'int'>, choices=None, required=False, help='(int, default=32) used for visual tokens', metavar=None), '--instr_size': _StoreAction(option_strings=['--instr_size'], dest='instr_size', nargs=None, const=None, default=512, type=<class 'int'>, choices=None, required=False, help='(int, default=512) ', metavar=None), '--mask_obs_prob': _StoreAction(option_strings=['--mask_obs_prob'], dest='mask_obs_prob', nargs=None, const=None, default=0.0, type=<class 'float'>, choices=None, required=False, help='(float, default=0.0) ', metavar=None), '--num_layers': _StoreAction(option_strings=['--num_layers'], dest='num_layers', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, required=False, help='(int, default=1) ', metavar=None), '--cross_layers': _StoreAction(option_strings=['--cross_layers'], dest='cross_layers', nargs=None, const=None, default=3, type=<class 'int'>, choices=None, required=False, help="(int, default=3) will be double for LAVA since it doesn't have policy", metavar=None), '--policy_layers': _StoreAction(option_strings=['--policy_layers'], dest='policy_layers', nargs=None, const=None, default=3, type=<class 'int'>, choices=None, required=False, help='(int, default=3) ', metavar=None), '--expert_counts': _StoreAction(option_strings=['--expert_counts'], dest='expert_counts', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, required=False, help='(int, default=1) default 1, if using VALA, then 6 = 2 modalities x 3 views', metavar=None), '--modality_fusion': _StoreTrueAction(option_strings=['--modality_fusion'], dest='modality_fusion', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) whether we fuse lang_goal and vision or not', metavar=None), '--position_offset': _StoreFalseAction(option_strings=['--position_offset'], dest='position_offset', nargs=0, const=False, default=True, type=None, choices=None, required=False, help='(bool, default=True) ', metavar=None), '--lang_offset': _StoreTrueAction(option_strings=['--lang_offset'], dest='lang_offset', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) ', metavar=None), '--offset_emb': _StoreTrueAction(option_strings=['--offset_emb'], dest='offset_emb', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) add multi-view and time embedding before making a prediction', metavar=None), '--no_film': _StoreFalseAction(option_strings=['--no_film'], dest='no_film', nargs=0, const=False, default=True, type=None, choices=None, required=False, help='(bool, default=True) use for debuggging', metavar=None), '--max_episode_length': _StoreAction(option_strings=['--max_episode_length'], dest='max_episode_length', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='(int, default=10) ', metavar=None), '--oracle_goal': _StoreTrueAction(option_strings=['--oracle_goal'], dest='oracle_goal', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) we manually provide sub-goal per step', metavar=None), '--log_to_wandb': _StoreTrueAction(option_strings=['--log_to_wandb'], dest='log_to_wandb', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='(bool, default=False) ', metavar=None), '-h': _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, required=False, help='show this help message and exit', metavar=None), '--help': _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, required=False, help='show this help message and exit', metavar=None)}, '_action_groups': [<argparse._ArgumentGroup object at 0x7fc14526ba30>, <argparse._ArgumentGroup object at 0x7fc14526be50>], '_mutually_exclusive_groups': [], '_defaults': {}, '_negative_number_matcher': re.compile('^-\\d+$|^-\\d*\\.\\d+$'), '_has_negative_number_optionals': [], 'prog': 'train.py', 'usage': None, 'epilog': None, 'formatter_class': <class 'argparse.HelpFormatter'>, 'fromfile_prefix_chars': None, 'add_help': True, 'allow_abbrev': True, 'exit_on_error': True, '_positionals': <argparse._ArgumentGroup object at 0x7fc14526ba30>, '_optionals': <argparse._ArgumentGroup object at 0x7fc14526be50>, '_subparsers': None, 'args_from_configs': [], 'accumulate_grad_batches': 1, 'cameras': ('wrist', 'left_shoulder', 'right_shoulder'), 'checkpoint': None, 'checkpoint_period': 10, 'dataset': ['/home/yiqiw2/experiment/language_rl/train_datasets/'], 'dataset_val': ['/home/yiqiw2/experiment/language_rl/val_datasets/'], 'device': 'cuda:1', 'xp': PosixPath('/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/xp'), 'name': 'VALA', 'num_workers': 5, 'max_tries': 10, 'max_episodes_per_taskvar': 100, 'instructions': None, 'cache_size': 100, 'lang_emb': 'W2V', 'seed': 2, 'tasks': ['push_buttons'], 'variations': ['10', '1'], 'val_variations': ['10', '1'], 'episodes_json_path': '/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Preprocess/episodes.json', 'val_number': 40, 'batch_size': 32, 'lr': 0.0005, 'warmup': 666, 'val_batch_size': 1, 'train_iters': 2000, 'jitter': False, 'load_model': False, 'load_name': '', 'save_model': False, 'save_path': '/home/yiqiw2/experiment/language_rl/saved_model', 'headless': True, 'output': PosixPath('/home/yiqiw2/experiment/language_rl/TemporalLatentGoal/Train/records.txt'), 'depth': 5, 'dim_feedforward': 512, 'hidden_dim': 32, 'instr_size': 512, 'mask_obs_prob': 0.0, 'num_layers': 1, 'cross_layers': 3, 'policy_layers': 3, 'expert_counts': 1, 'modality_fusion': False, 'position_offset': True, 'lang_offset': False, 'offset_emb': False, 'no_film': True, 'max_episode_length': 10, 'oracle_goal': True, 'log_to_wandb': True}
2023-03-23 11:18:21,867 INFO    MainThread:71344 [wandb_init.py:init():588] starting backend
2023-03-23 11:18:21,867 INFO    MainThread:71344 [wandb_init.py:init():592] setting up manager
2023-03-23 11:18:21,869 INFO    MainThread:71344 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-03-23 11:18:21,870 INFO    MainThread:71344 [wandb_init.py:init():599] backend started and connected
2023-03-23 11:18:21,878 INFO    MainThread:71344 [wandb_init.py:init():687] updated telemetry
2023-03-23 11:18:21,891 INFO    MainThread:71344 [wandb_init.py:init():727] communicating run to backend with 60.0 second timeout
2023-03-23 11:18:22,232 INFO    MainThread:71344 [wandb_run.py:_on_init():2134] communicating current version
2023-03-23 11:18:22,333 INFO    MainThread:71344 [wandb_run.py:_on_init():2143] got version response upgrade_message: "wandb version 0.14.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-03-23 11:18:22,334 INFO    MainThread:71344 [wandb_init.py:init():775] starting run threads in backend
2023-03-23 11:18:24,246 INFO    MainThread:71344 [wandb_run.py:_console_start():2114] atexit reg
2023-03-23 11:18:24,246 INFO    MainThread:71344 [wandb_run.py:_redirect():1969] redirect: SettingsConsole.WRAP_RAW
2023-03-23 11:18:24,246 INFO    MainThread:71344 [wandb_run.py:_redirect():2034] Wrapping output streams.
2023-03-23 11:18:24,246 INFO    MainThread:71344 [wandb_run.py:_redirect():2059] Redirects installed.
2023-03-23 11:18:24,247 INFO    MainThread:71344 [wandb_init.py:init():817] run started, returning control to user process
2023-03-23 11:37:51,651 WARNING MsgRouterThr:71344 [router.py:message_loop():77] message_loop has been closed
